{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as torch_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('longet train comment length',train_max_len)\n",
    "print('longest train title length',train_max_title_len)\n",
    "print(len(train_text))\n",
    "print(len(train_title))\n",
    "print(train_labels.shape)\n",
    "\n",
    "\"\"\"\n",
    "longet train comment length 244\n",
    "longest train title length 13\n",
    "1528\n",
    "1528\n",
    "(1528,)\n",
    "\"\"\"\n",
    "\n",
    "print('longest test comment length', test_max_len)\n",
    "print('longest test title length', test_max_title_len)\n",
    "print(len(test_text))\n",
    "print(len(test_title))\n",
    "print(test_labels.shape)\n",
    "\n",
    "\"\"\"\n",
    "longest test comment length 126\n",
    "longest test title length 19\n",
    "102\n",
    "102\n",
    "(102,)\n",
    "\"\"\"\n",
    "\n",
    "print(train_data_array.shape, train_title_array.shape)\n",
    "print(test_data_array.shape, test_title_array.shape)\n",
    "\"\"\"\n",
    "(244, 1528, 300) (13, 1528, 300)\n",
    "(126, 102, 300) (19, 102, 300)\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "data_array.shape = (244, 1528, 300)\n",
    "data_labels.shape = (1528,)\n",
    "data is an (L,N,D) array\n",
    "L = max_length of sequence\n",
    "N = batch_size\n",
    "D = embed_dim\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module): # single direction lstm, no attention\n",
    "  def __init__(self, hidden_size = 100, embed_dim = 300):\n",
    "    super(BaseModel, self).__init__()\n",
    "    \n",
    "    self.hidden_size = hidden_size\n",
    "    \n",
    "    self.lstm = nn.LSTM(input_size = embed_dim, hidden_size = hidden_size, num_layers = 1, batch_first = True, dropout = 0.2, bidirectional = False)\n",
    "    \n",
    "    # two linear layers for context (final hidden state) => binary classification\n",
    "    self.linear1 = nn.Linear(hidden_size, 150) \n",
    "    self.linear2 = nn.Linear(150, 1)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, data):\n",
    "    \"\"\"\n",
    "    data is an (N, L, D) = (batch_size, max_length, embed_dim) array\n",
    "    returns an (N,1) array of binary probabilities that each comment is hateful\n",
    "    \"\"\"\n",
    "    hidden_states, (_, _) = self.lstm(data)\n",
    "    # hidden_states = (batch_size, max_length, embed_dim) array\n",
    "    \n",
    "    sentences = torch.sum(hidden_states, axis = 1 )\n",
    "\n",
    "    return self.sigmoid(torch.squeeze(self.linear2(self.relu(self.linear1(sentences)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module): # single direction lstm, no attention\n",
    "  def __init__(self, hidden_size = 100, embed_dim = 300, bidi = True, attention = True):\n",
    "    super(BaseModel, self).__init__()\n",
    "    \n",
    "    self.hidden_size = hidden_size\n",
    "    \n",
    "    self.lstm = nn.LSTM(input_size = embed_dim, hidden_size = hidden_size, num_layers = 1, batch_first = True, dropout = 0.2, bidirectional = False)\n",
    "    \n",
    "    # two linear layers for context (final hidden state) => binary classification\n",
    "    self.linear1 = nn.Linear(hidden_size, 150) \n",
    "    self.linear2 = nn.Linear(150, 1)\n",
    "\n",
    "    self.relu = nn.ReLU()\n",
    "\n",
    "    self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, data):\n",
    "    \"\"\"\n",
    "    data is an (N, L, D) = (batch_size, max_length, embed_dim) array\n",
    "    returns an (N,1) array of binary probabilities that each comment is hateful\n",
    "    \"\"\"\n",
    "    hidden_states, (_, _) = self.lstm(data)\n",
    "    # hidden_states = (batch_size, max_length, embed_dim) array\n",
    "    \n",
    "    sentences = torch.sum(hidden_states, axis = 1 )\n",
    "\n",
    "    return self.sigmoid(torch.squeeze(self.linear2(self.relu(self.linear1(sentences)))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
